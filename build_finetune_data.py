# build_finetune_data_hybrid.py
import json
import random
from collections import defaultdict, Counter
from pathlib import Path

# === è¼¸å…¥/è¼¸å‡º ===
TRAIN_JSONL = "train.jsonl"
PRED_JSONL  = "predictions.jsonl"  # ä¾†æºæ–¼ä½ å…ˆå‰çš„è©•ä¼°è¼¸å‡ºï¼šæ¯è¡Œå« id, title, true, pred
OUT_JSONL   = "finetune_pairs.jsonl"

# === æ˜¯å¦ä½¿ç”¨ Chroma è¿‘é„°ï¼ˆåƒ…æŸ¥ train å‘é‡åº«ï¼‰===
USE_CHROMA = True
CHROMA_DB_PATH = "chroma_db"
CHROMA_COLLECTION = "gov_letters"
E5_MODEL_NAME = "intfloat/multilingual-e5-large"

# === æ‰‹å‹•æ··æ·†å°ï¼ˆå¯èª¿æ•´/æ“´å……ï¼‰===
CONFUSABLE = {
    "ä¿å–®æŸ¥è©¢": ["ä¿å–®è¨»è¨˜", "ä¿å–®æŸ¥è©¢ï¼‹è¨»è¨˜"],
    "ä¿å–®è¨»è¨˜": ["ä¿å–®æŸ¥è©¢", "ä¿å–®æŸ¥è©¢ï¼‹è¨»è¨˜", "é€šçŸ¥å‡½"],
    "ä¿å–®æŸ¥è©¢ï¼‹è¨»è¨˜": ["ä¿å–®æŸ¥è©¢", "ä¿å–®è¨»è¨˜"],
    "æ”¶å–ï¼‹æ’¤éŠ·": ["æ”¶å–ä»¤"],
    "æ”¶å–ä»¤": ["æ”¶å–ï¼‹æ’¤éŠ·"],
}

# === æ¯å€‹ anchor çš„æŠ½æ¨£é‡ï¼ˆå¯èª¿ï¼‰===
POS_PER_ANCHOR = 2
HN_FROM_CONFUSABLE_PER_ANCHOR = 2
HN_FROM_CHROMA_PER_ANCHOR = 3
HN_FROM_PRED_LABELS_PER_ANCHOR = 2   # ä¾ predictions æ‰¾åˆ°çš„ã€Œå¸¸è¦‹èª¤åˆ¤é¡žåˆ¥ã€ä¾†è£œè² ä¾‹

RANDOM_SEED = 42
random.seed(RANDOM_SEED)

def read_jsonl(p):
    with open(p, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                yield json.loads(line)

def load_by_label(jsonl_path):
    by_label = defaultdict(list)
    for rec in read_jsonl(jsonl_path):
        by_label[rec["label"]].append(rec["title"])
    return by_label

def load_titles_with_labels(jsonl_path):
    items = []
    for rec in read_jsonl(jsonl_path):
        items.append((str(rec.get("id")), rec["title"], rec["label"]))
    return items

def load_pred_label_map(pred_path):
    """
    è®€ predictions.jsonlï¼ˆä¸è®€ test.jsonl æ­£æ–‡ï¼‰ï¼Œ
    å›žå‚³ï¼šmislabel_stats[true_label] = Counter({pred_label: count, ...})
    åƒ…ç”¨ã€Œèª¤åˆ¤çš„é¡žåˆ¥åç¨±ã€è¨Šè™Ÿä¾†æ±ºå®šè¨“ç·´æ™‚è©²å¼·åŒ–å“ªäº›è² ä¾‹é¡žåˆ¥ï¼›è² ä¾‹æ–‡æœ¬ä»å¾ž train å–ã€‚
    """
    stats = defaultdict(Counter)
    if not Path(pred_path).exists():
        return stats
    for rec in read_jsonl(pred_path):
        true_lb = rec.get("true")
        pred_lb = rec.get("pred")
        if true_lb and pred_lb and pred_lb != true_lb:
            stats[true_lb][pred_lb] += 1
    return stats

def safe_sample(lst, k, exclude=None):
    if not lst:
        return []
    pool = lst if exclude is None else [x for x in lst if x != exclude]
    if not pool:
        return []
    if k >= len(pool):
        return list(pool)
    return random.sample(pool, k)

# --- Chroma è¿‘é„°ï¼šåƒ…æŸ¥ train å‘é‡åº« ---
def setup_chroma():
    try:
        import chromadb
        from sentence_transformers import SentenceTransformer
        client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        col = client.get_collection(CHROMA_COLLECTION)
        encoder = SentenceTransformer(E5_MODEL_NAME)
        return col, encoder
    except Exception as e:
        print(f"[Chroma] åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
        return None, None

def chroma_hard_negs(col, encoder, text, true_label, topn=20):
    try:
        q = encoder.encode([text], normalize_embeddings=True).tolist()
        res = col.query(query_embeddings=q, n_results=topn)
        metas = res.get("metadatas", [[]])[0]
        docs  = res.get("documents", [[]])[0]
        cand = []
        for m, d in zip(metas, docs):
            lb = m.get("label")
            if lb and lb != true_label:
                cand.append(d)
        return cand
    except Exception:
        return []

def main():
    if not Path(TRAIN_JSONL).exists():
        raise FileNotFoundError(f"{TRAIN_JSONL} ä¸å­˜åœ¨")
    if not Path(PRED_JSONL).exists():
        print(f"âš ï¸ æ‰¾ä¸åˆ° {PRED_JSONL}ï¼Œå°‡ä¸ä½¿ç”¨é æ¸¬èª¤åˆ¤è¨Šè™Ÿã€‚")

    # 1) è®€å– train
    train_by_label = load_by_label(TRAIN_JSONL)
    train_items = load_titles_with_labels(TRAIN_JSONL)  # [(id, title, label)]

    # 2) è®€å– predictions.jsonl â†’ å½¢æˆ true_label â†’ å¸¸è¦‹èª¤åˆ¤çš„ pred_labels
    mislabel_stats = load_pred_label_map(PRED_JSONL)
    # è½‰æˆï¼štrue_label -> list of pred_labelsï¼ˆä¾å‡ºç¾æ¬¡æ•¸æŽ’åºï¼‰
    mislabel_labels = {lb: [plb for plb, _cnt in cnts.most_common()] 
                       for lb, cnts in mislabel_stats.items()}

    # 3) Chromaï¼ˆåƒ…æŸ¥ train å‘é‡åº«ï¼‰
    col = enc = None
    if USE_CHROMA:
        col, enc = setup_chroma()
        if col is None:
            print("âš ï¸ é—œé–‰ USE_CHROMAï¼ˆåˆå§‹åŒ–å¤±æ•—ï¼‰")
            USE_CHROMA = False

    # 4) ç‚ºæ¯å€‹ train çš„å¥å­ç”¢ç”Ÿ (anchor, positives, hard_negatives)
    out_cnt = 0
    with open(OUT_JSONL, "w", encoding="utf-8") as f:
        for _id, anchor_text, true_lb in train_items:
            # positivesï¼šåŒé¡žï¼ˆtrainï¼‰
            positives = safe_sample(train_by_label.get(true_lb, []), POS_PER_ANCHOR, exclude=anchor_text)

            # hard negatives ä¾†æºé›†åˆ
            neg_set = set()

            # a) æ‰‹å‹•æ··æ·†å°
            for clb in CONFUSABLE.get(true_lb, []):
                for t in safe_sample(train_by_label.get(clb, []), HN_FROM_CONFUSABLE_PER_ANCHOR, exclude=anchor_text):
                    neg_set.add(t)

            # b) ç”± predictions.jsonl è§€å¯Ÿåˆ°çš„ã€Œå¸¸è¦‹èª¤åˆ¤é¡žåˆ¥ã€
            #    åªæ‹¿ã€Œé¡žåˆ¥åç¨±ã€ç•¶è¨Šè™Ÿï¼Œå¯¦éš›è² ä¾‹æ–‡æœ¬ä»å¾ž train å–
            for plb in mislabel_labels.get(true_lb, [])[:3]:  # æœ€å¸¸è¦‹çš„å‰ä¸‰å€‹èª¤åˆ¤é¡žåˆ¥
                for t in safe_sample(train_by_label.get(plb, []), HN_FROM_PRED_LABELS_PER_ANCHOR, exclude=anchor_text):
                    neg_set.add(t)

            # c) Chroma è¿‘é„°ï¼ˆç•°é¡žï¼‰
            if USE_CHROMA and col and enc:
                cands = chroma_hard_negs(col, enc, anchor_text, true_lb, topn=20)
                for t in cands[:HN_FROM_CHROMA_PER_ANCHOR]:
                    neg_set.add(t)

            negatives = list(neg_set)

            if positives and negatives:
                rec = {"anchor": anchor_text, "positive": positives, "hard_negative": negatives}
                f.write(json.dumps(rec, ensure_ascii=False) + "\n")
                out_cnt += 1

    # 5) æ‘˜è¦
    print(f"âœ… å·²è¼¸å‡º {out_cnt} è¡Œåˆ° {OUT_JSONL}")
    if out_cnt == 0:
        print("âš ï¸ æ²’æœ‰ä»»ä½• anchor åŒæ™‚å…·å‚™ positive èˆ‡ hard_negativeã€‚")
        print("   å»ºè­°ï¼šæ“´å…… CONFUSABLEã€æ”¾å¯¬æ¯ anchor æŠ½æ¨£æ•¸ï¼Œæˆ–å•Ÿç”¨/ä¿®æ­£ Chromaã€‚")

    # é¡å¤–åˆ—å‡ºæ¯å€‹ true_label çš„ã€Œä¾†è‡ª predictions çš„å¸¸è¦‹èª¤åˆ¤æ–¹å‘ã€
    if mislabel_stats:
        print("\nðŸ”Ž ç”± predictions.jsonl æŽ¨å¾—çš„å¸¸è¦‹èª¤åˆ¤æ–¹å‘ï¼ˆtrue -> pred: countï¼‰ï¼š")
        for lb in sorted(mislabel_stats.keys()):
            row = ", ".join(f"{plb}:{cnt}" for plb, cnt in mislabel_stats[lb].most_common())
            print(f"  {lb} -> {row}")

if __name__ == "__main__":
    main()
